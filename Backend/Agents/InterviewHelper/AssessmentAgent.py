"""
üß™ Assessment Agent
Handles assessment-related queries and integrates with the Assessment Engine

This agent processes natural language queries related to assessments and manages
the complete assessment workflow from creation to result analysis.
"""

import json
import os
from typing import Dict, List, Optional, Any
from Backend.Agents.InterviewHelper.AssessmentEngine import (
    AssessmentEngine, AssessmentConfig, AssessmentType, DifficultyLevel
)
from Backend.Agents.InterviewHelper.CompanyIntelligenceEngine import CompanyIntelligenceEngine
from Backend.Agents.InterviewHelper.ResumeBuilder import ResumeBuilder

class AssessmentAgent:
    """Agent for handling assessment-related queries"""
    
    def __init__(self):
        self.assessment_engine = AssessmentEngine()
        self.company_engine = CompanyIntelligenceEngine()
        self.resume_builder = ResumeBuilder()
        
        # Cache for session data
        self.current_assessment = None
        self.user_context = {}
    
    def process_query(self, query: str) -> str:
        """Process assessment-related queries"""
        
        query_lower = query.lower()
        
        # Assessment creation queries
        if any(keyword in query_lower for keyword in ['create assessment', 'start test', 'begin assessment']):
            return self._handle_assessment_creation(query)
        
        # Assessment status queries
        elif any(keyword in query_lower for keyword in ['assessment status', 'test progress', 'current test']):
            return self._handle_assessment_status(query)
        
        # Question-related queries
        elif any(keyword in query_lower for keyword in ['submit answer', 'answer question', 'next question']):
            return self._handle_question_interaction(query)
        
        # Results and analytics
        elif any(keyword in query_lower for keyword in ['results', 'score', 'performance', 'analysis']):
            return self._handle_results_query(query)
        
        # Assessment information
        elif any(keyword in query_lower for keyword in ['assessment info', 'test types', 'available assessments']):
            return self._handle_info_query(query)
        
        # Company-specific assessments
        elif any(keyword in query_lower for keyword in ['company test', 'company assessment', 'prepare for']):
            return self._handle_company_assessment(query)
        
        # DSA practice
        elif any(keyword in query_lower for keyword in ['dsa practice', 'coding practice', 'algorithm practice']):
            return self._handle_dsa_practice(query)
        
        # General help
        else:
            return self._handle_general_help(query)
    
    def _handle_assessment_creation(self, query: str) -> str:
        """Handle assessment creation requests"""
        
        try:
            # Parse company and role from query
            company_name, role = self._extract_company_and_role(query)
            
            if not company_name or not role:
                return self._get_assessment_creation_guide()
            
            # Get company intelligence
            print(f"üîç Gathering intelligence for {role} at {company_name}...")
            company_intelligence = self.company_engine.research_company(company_name, role)
            
            # Get user's resume data (this would come from Phase 2)
            resume_data = self._get_user_resume_data()
            
            # Create customized assessment
            config = self.assessment_engine.create_company_specific_assessment(
                company_intelligence, resume_data, role
            )
            
            # Start the assessment
            session_info = self.assessment_engine.start_assessment(config)
            self.current_assessment = config.assessment_id
            
            return f"""
üéØ **{config.name} Created Successfully!**

üìä **Assessment Details:**
‚Ä¢ **Company**: {company_name}
‚Ä¢ **Role**: {role}  
‚Ä¢ **Total Questions**: {config.total_questions}
‚Ä¢ **Time Limit**: {config.time_limit_minutes} minutes
‚Ä¢ **Passing Score**: {config.passing_score}%

üìù **Question Distribution:**
‚Ä¢ **DSA Coding**: {config.dsa_questions} questions
‚Ä¢ **Technical MCQ**: {config.mcq_questions} questions  
‚Ä¢ **Aptitude**: {config.aptitude_questions} questions

üéÆ **Assessment Started!**
Assessment ID: `{config.assessment_id}`

Ready to begin? Say "start first question" or "show me question 1" to proceed!

üí° **Tips:**
‚Ä¢ Read questions carefully before answering
‚Ä¢ Manage your time effectively ({config.time_limit_minutes} minutes total)
‚Ä¢ Use hints when available for coding questions
‚Ä¢ You can ask for clarification on any question
"""
            
        except Exception as e:
            return f"‚ùå Error creating assessment: {str(e)}\n\nPlease try again with a specific company and role, e.g., 'Create assessment for Software Engineer at Google'"
    
    def _handle_assessment_status(self, query: str) -> str:
        """Handle assessment status queries"""
        
        if not self.current_assessment:
            return "üìã **No Active Assessment**\n\nYou don't have any active assessments. Say 'create assessment for [role] at [company]' to start a new one!"
        
        # Get current session info
        session = self.assessment_engine.active_assessments.get(self.current_assessment)
        
        if not session:
            return "‚ùå Assessment session not found. Please start a new assessment."
        
        progress = session['current_question']
        total = len(session['questions'])
        time_elapsed = session.get('time_elapsed', 0)
        
        return f"""
üìä **Assessment Progress**

üéØ **Current Status**: Question {progress + 1} of {total}
‚è∞ **Time Elapsed**: {time_elapsed} minutes
üìà **Progress**: {(progress / total) * 100:.1f}% complete

üîÑ **Next Steps**:
‚Ä¢ Say "show current question" to see the active question
‚Ä¢ Say "submit answer [your answer]" to answer
‚Ä¢ Say "get hint" for coding questions

üí™ Keep going! You're doing great!
"""
    
    def _handle_question_interaction(self, query: str) -> str:
        """Handle question interactions (submit, next, hints)"""
        
        if not self.current_assessment:
            return "‚ùå No active assessment. Please start an assessment first."
        
        session = self.assessment_engine.active_assessments.get(self.current_assessment)
        if not session:
            return "‚ùå Assessment session not found."
        
        query_lower = query.lower()
        
        # Show current question
        if 'show' in query_lower and ('question' in query_lower or 'current' in query_lower):
            current_idx = session['current_question']
            if current_idx < len(session['questions']):
                question = session['questions'][current_idx]
                return self._format_question_display(question, current_idx + 1, len(session['questions']))
            else:
                return "üéâ Assessment completed! Say 'show results' to see your performance."
        
        # Submit answer
        elif 'submit' in query_lower or 'answer' in query_lower:
            return self._handle_answer_submission(query, session)
        
        # Get hint
        elif 'hint' in query_lower:
            return self._provide_hint(session)
        
        return "‚ùì I can help you with:\n‚Ä¢ 'show current question'\n‚Ä¢ 'submit answer [your answer]'\n‚Ä¢ 'get hint' (for coding questions)"
    
    def _handle_results_query(self, query: str) -> str:
        """Handle results and performance queries"""
        
        # Get recent assessment results
        stats = self.assessment_engine.get_assessment_stats()
        
        return f"""
üìä **Assessment System Statistics**

üìà **Question Database**:
‚Ä¢ DSA Questions: {stats['total_dsa_questions']}
‚Ä¢ Technical MCQs: {stats['total_mcq_questions']} 
‚Ä¢ Aptitude Questions: {stats['total_aptitude_questions']}

üè¢ **Supported Companies**: {len(stats['supported_companies'])}
{', '.join(stats['supported_companies'][:10])}{'...' if len(stats['supported_companies']) > 10 else ''}

üéÆ **Active Sessions**: {stats['active_assessments']}

üí° **Available Commands**:
‚Ä¢ "show my results" - View recent assessment results
‚Ä¢ "create assessment for [role] at [company]" - Start new test
‚Ä¢ "assessment analytics" - Detailed performance analysis
"""
    
    def _handle_info_query(self, query: str) -> str:
        """Handle information queries about assessments"""
        
        return """
üß™ **NEXUS Assessment System - Phase 3**

üéØ **Assessment Types Available**:

**1. DSA Coding Challenges** üß†
‚Ä¢ Algorithm implementation problems
‚Ä¢ Data structure manipulation
‚Ä¢ Time/space complexity optimization
‚Ä¢ Real coding interview simulation

**2. Technical MCQs** üíª
‚Ä¢ Programming language concepts
‚Ä¢ System design principles
‚Ä¢ Database management
‚Ä¢ Software engineering practices

**3. Aptitude Tests** üìä
‚Ä¢ Quantitative reasoning
‚Ä¢ Logical puzzles
‚Ä¢ Pattern recognition
‚Ä¢ Verbal ability

**4. Company-Specific Assessments** üè¢
‚Ä¢ Customized based on company intelligence
‚Ä¢ Role-specific question selection
‚Ä¢ Industry-standard difficulty levels
‚Ä¢ Real interview pattern matching

üéÆ **Features**:
‚Ä¢ ‚è∞ Timed test environments
‚Ä¢ üìä Real-time progress tracking  
‚Ä¢ üí° Intelligent hint system
‚Ä¢ üìà Detailed performance analytics
‚Ä¢ üéØ Adaptive difficulty based on experience
‚Ä¢ üîÑ Seamless integration with Phase 1 & 2 data

üìù **Getting Started**:
Say: "Create assessment for Software Engineer at Google"
"""
    
    def _handle_company_assessment(self, query: str) -> str:
        """Handle company-specific assessment queries"""
        
        company_name, role = self._extract_company_and_role(query)
        
        if company_name:
            # Get company assessment info
            company_info = self.company_engine.get_company_assessment_pattern(company_name)
            
            return f"""
üè¢ **{company_name} Assessment Information**

üéØ **Typical Assessment Pattern**:
‚Ä¢ **Interview Rounds**: {company_info.get('rounds', '3-4')}
‚Ä¢ **Focus Areas**: {', '.join(company_info.get('focus_areas', ['Technical Skills', 'Problem Solving']))}
‚Ä¢ **Difficulty Level**: {company_info.get('difficulty', 'Medium to Hard')}

üìä **Question Types**:
‚Ä¢ **DSA Problems**: {company_info.get('dsa_percentage', '60')}%
‚Ä¢ **Technical MCQs**: {company_info.get('mcq_percentage', '30')}%
‚Ä¢ **System Design**: {company_info.get('system_design', '10')}%

‚è∞ **Time Allocation**:
‚Ä¢ **Total Duration**: {company_info.get('duration', '90')} minutes
‚Ä¢ **Per Question**: {company_info.get('time_per_question', '4-5')} minutes average

üí° **Preparation Tips**:
‚Ä¢ Focus on {', '.join(company_info.get('key_topics', ['Arrays', 'Trees', 'Dynamic Programming']))}
‚Ä¢ Practice {company_info.get('recommended_problems', '50-100')} problems
‚Ä¢ Review {', '.join(company_info.get('technologies', ['Data Structures', 'Algorithms']))}

üöÄ **Ready to Practice?**
Say: "Create assessment for {role or 'Software Engineer'} at {company_name}"
"""
        
        return """
üè¢ **Company Assessment Preparation**

To get company-specific assessment information, please specify:

**Format**: "Prepare for [role] at [company]"

**Examples**:
‚Ä¢ "Prepare for Software Engineer at Google"  
‚Ä¢ "Assessment for Data Scientist at Microsoft"
‚Ä¢ "Test for Frontend Developer at Amazon"

I'll provide:
‚úÖ Company-specific question patterns
‚úÖ Difficulty levels and focus areas  
‚úÖ Time allocation strategies
‚úÖ Key topics to prepare
‚úÖ Customized practice assessments
"""
    
    def _handle_dsa_practice(self, query: str) -> str:
        """Handle DSA practice requests"""
        
        # Extract difficulty level or topic from query
        difficulty = self._extract_difficulty(query)
        topic = self._extract_topic(query)
        
        practice_info = {
            'available_topics': [
                'Arrays', 'Strings', 'Linked Lists', 'Trees', 'Graphs',
                'Dynamic Programming', 'Sorting & Searching', 'Stack & Queue'
            ],
            'difficulty_levels': ['Easy', 'Medium', 'Hard'],
            'total_problems': len(self.assessment_engine.dsa_questions)
        }
        
        return f"""
üß† **DSA Practice System**

üìö **Available Topics** ({practice_info['total_problems']} total problems):
{chr(10).join(['‚Ä¢ ' + topic for topic in practice_info['available_topics']])}

üéØ **Difficulty Levels**:
‚Ä¢ **Easy**: Foundation building problems
‚Ä¢ **Medium**: Interview-level challenges  
‚Ä¢ **Hard**: Advanced algorithmic thinking

üéÆ **Practice Modes**:
‚Ä¢ **Topic-wise**: Focus on specific data structures
‚Ä¢ **Company-wise**: Practice problems from target companies
‚Ä¢ **Random Practice**: Mixed difficulty and topics
‚Ä¢ **Timed Challenges**: Simulate real interview pressure

üöÄ **Start Practicing**:
‚Ä¢ "Create DSA practice on Arrays"
‚Ä¢ "Medium difficulty tree problems"  
‚Ä¢ "Google coding questions"
‚Ä¢ "Random DSA challenge"

üí° **Features**:
‚Ä¢ Real-time code execution
‚Ä¢ Multiple test case validation
‚Ä¢ Hint system for guidance
‚Ä¢ Performance tracking
‚Ä¢ Solution explanations
"""
    
    def _handle_general_help(self, query: str) -> str:
        """Handle general help and unknown queries"""
        
        return """
üß™ **NEXUS Assessment Helper - Available Commands**

üéØ **Start Assessment**:
‚Ä¢ "Create assessment for [role] at [company]"
‚Ä¢ "Start test for Software Engineer at Google"
‚Ä¢ "Begin assessment for Data Scientist"

üìä **Assessment Management**:
‚Ä¢ "Show current question" 
‚Ä¢ "Submit answer [your answer]"
‚Ä¢ "Get hint" (for coding questions)
‚Ä¢ "Assessment status"

üìà **Results & Analytics**:
‚Ä¢ "Show my results"
‚Ä¢ "Assessment performance"
‚Ä¢ "Strengths and weaknesses"

üè¢ **Company Preparation**:
‚Ä¢ "Prepare for Google interview"
‚Ä¢ "Amazon assessment pattern"
‚Ä¢ "Microsoft technical test info"

üß† **Practice Modes**:  
‚Ä¢ "DSA practice on trees"
‚Ä¢ "Technical MCQ practice"
‚Ä¢ "Aptitude test practice"

‚ùì **Need Help?**
‚Ä¢ "Assessment info" - System overview
‚Ä¢ "Available companies" - Supported companies
‚Ä¢ "Question types" - Assessment categories

Just ask me anything about assessments, coding practice, or interview preparation!
"""
    
    def _extract_company_and_role(self, query: str) -> tuple:
        """Extract company name and role from query"""
        
        # Common company names
        companies = [
            'Google', 'Microsoft', 'Amazon', 'Facebook', 'Meta', 'Apple',
            'Netflix', 'Tesla', 'IBM', 'Oracle', 'Adobe', 'Salesforce',
            'Uber', 'Lyft', 'Twitter', 'LinkedIn', 'Spotify', 'Airbnb'
        ]
        
        # Common roles
        roles = [
            'Software Engineer', 'Data Scientist', 'Frontend Developer',
            'Backend Developer', 'Full Stack Developer', 'DevOps Engineer',
            'Product Manager', 'UI/UX Designer', 'ML Engineer', 'SDE',
            'Senior Software Engineer', 'Principal Engineer'
        ]
        
        query_lower = query.lower()
        
        # Find company
        found_company = None
        for company in companies:
            if company.lower() in query_lower:
                found_company = company
                break
        
        # Find role
        found_role = None
        for role in roles:
            if role.lower() in query_lower:
                found_role = role
                break
        
        # Try to extract using common patterns
        if ' at ' in query_lower:
            parts = query_lower.split(' at ')
            if len(parts) >= 2:
                # Role should be before 'at', company after
                role_part = parts[0].strip()
                company_part = parts[1].strip()
                
                # Find role in the first part
                for role in roles:
                    if role.lower() in role_part:
                        found_role = role
                        break
                
                # Find company in the second part
                for company in companies:
                    if company.lower() in company_part:
                        found_company = company
                        break
        
        return found_company, found_role
    
    def _extract_difficulty(self, query: str) -> Optional[str]:
        """Extract difficulty level from query"""
        query_lower = query.lower()
        
        if 'easy' in query_lower:
            return 'Easy'
        elif 'medium' in query_lower:
            return 'Medium'
        elif 'hard' in query_lower:
            return 'Hard'
        
        return None
    
    def _extract_topic(self, query: str) -> Optional[str]:
        """Extract topic from query"""
        query_lower = query.lower()
        
        topics_map = {
            'array': 'Arrays',
            'string': 'Strings', 
            'linked list': 'Linked Lists',
            'tree': 'Trees',
            'graph': 'Graphs',
            'dp': 'Dynamic Programming',
            'dynamic programming': 'Dynamic Programming',
            'sort': 'Sorting & Searching',
            'search': 'Sorting & Searching',
            'stack': 'Stack & Queue',
            'queue': 'Stack & Queue'
        }
        
        for keyword, topic in topics_map.items():
            if keyword in query_lower:
                return topic
        
        return None
    
    def _get_user_resume_data(self) -> Dict:
        """Get user's resume data from Phase 2"""
        # This would integrate with the ResumeBuilder to get actual user data
        # For now, return mock data
        
        return {
            'experience_level': 'Mid Level',
            'skills': ['Python', 'JavaScript', 'React', 'Node.js'],
            'years_experience': 4,
            'education': 'Bachelor\'s in Computer Science',
            'previous_roles': ['Software Developer', 'Frontend Developer']
        }
    
    def _get_assessment_creation_guide(self) -> str:
        """Return guide for creating assessments"""
        
        return """
üéØ **Create Your Custom Assessment**

To create a tailored assessment, please provide:

**Format**: "Create assessment for [ROLE] at [COMPANY]"

**Examples**:
‚úÖ "Create assessment for Software Engineer at Google"
‚úÖ "Start test for Data Scientist at Microsoft"  
‚úÖ "Begin assessment for Frontend Developer at Amazon"

üéÆ **What I'll Create**:
‚Ä¢ **Company-specific questions** based on their interview patterns
‚Ä¢ **Role-tailored content** matching job requirements
‚Ä¢ **Adaptive difficulty** based on your experience level  
‚Ä¢ **Realistic timing** simulating actual screening rounds

üí° **Popular Options**:
‚Ä¢ Google Software Engineer Assessment
‚Ä¢ Microsoft Data Scientist Test
‚Ä¢ Amazon Frontend Developer Challenge
‚Ä¢ Facebook Full Stack Engineer Exam

Ready to start? Just tell me the role and company!
"""
    
    def _format_question_display(self, question, current_num: int, total_num: int) -> str:
        """Format question for display"""
        
        if hasattr(question, 'title'):  # DSA Question
            return f"""
üß† **DSA Coding Challenge** - Question {current_num}/{total_num}

**{question.title}** ({question.difficulty.value})
üìÇ Category: {question.category.value}

**Problem Statement:**
{question.description}

**Test Cases:**
{chr(10).join([f"Input: {tc.input_data} ‚Üí Output: {tc.expected_output}" for tc in question.test_cases[:2]])}

üí° **Available Commands**:
‚Ä¢ "submit answer [your code/approach]" - Submit your solution
‚Ä¢ "get hint" - Get a helpful hint
‚Ä¢ "clarify question" - Ask for clarification

‚è∞ Take your time to understand the problem before coding!
"""
        
        else:  # MCQ Question
            options_text = '\n'.join([f"{opt.id.upper()}. {opt.text}" for opt in question.options])
            
            return f"""
üíª **Technical MCQ** - Question {current_num}/{total_num}

**{question.question}** ({question.difficulty.value})
üìÇ Category: {question.category.value}

**Options:**
{options_text}

üí° **How to Answer**:
‚Ä¢ "submit answer A" (or B, C, D)
‚Ä¢ "submit A" (short form)

Choose the best answer and submit when ready!
"""
    
    def _handle_answer_submission(self, query: str, session: Dict) -> str:
        """Handle answer submission"""
        
        # Extract answer from query
        query_lower = query.lower()
        
        # Get current question
        current_idx = session['current_question']
        if current_idx >= len(session['questions']):
            return "üéâ Assessment already completed! Say 'show results' to see your performance."
        
        current_question = session['questions'][current_idx]
        
        # Extract answer based on question type
        if hasattr(current_question, 'title'):  # DSA Question
            # For DSA, extract code or approach after "submit answer"
            if 'submit answer' in query_lower:
                answer = query[query_lower.find('submit answer') + 13:].strip()
            else:
                answer = query.strip()
        else:  # MCQ Question
            # Extract option (A, B, C, D)
            import re
            option_match = re.search(r'\b([ABCD])\b', query.upper())
            if option_match:
                # Convert A,B,C,D to actual option IDs
                option_letter = option_match.group(1)
                option_map = {'A': 'a', 'B': 'b', 'C': 'c', 'D': 'd'}
                answer = option_map.get(option_letter, 'a')
            else:
                return "‚ùì Please specify your answer (A, B, C, or D). Example: 'submit answer B'"
        
        # Submit answer
        result = self.assessment_engine.submit_answer(
            session['config'].assessment_id,
            current_question.id,
            answer
        )
        
        if 'error' in result:
            return f"‚ùå Error: {result['error']}"
        
        # Format response
        if result.get('completed'):
            return f"""
üéâ **Assessment Completed!**

‚úÖ **Final Results:**
‚Ä¢ **Total Score**: {result['total_score']:.1f}
‚Ä¢ **Percentage**: {result['percentage']:.1f}%
‚Ä¢ **Status**: {'‚úÖ PASSED' if result['passed'] else '‚ùå NEEDS IMPROVEMENT'}
‚Ä¢ **Time Taken**: {result['time_taken']}

üéØ **Performance Analysis:**

**Strengths** üí™:
{chr(10).join(['‚Ä¢ ' + strength for strength in result.get('strengths', ['Great effort!'])])}

**Areas for Improvement** üìö:
{chr(10).join(['‚Ä¢ ' + weakness for weakness in result.get('weaknesses', [])])}

**Recommendations** üí°:
{chr(10).join(['‚Ä¢ ' + rec for rec in result.get('recommendations', [])])}

üöÄ Want to practice more? Say "create new assessment" or "DSA practice"!
"""
        
        else:
            # Show result for current question and next question
            next_q_num = session['current_question'] + 1
            total_q = len(session['questions'])
            
            response = f"""
{'‚úÖ' if result['correct'] else '‚ùå'} **Answer {'Correct' if result['correct'] else 'Incorrect'}** 
Score: {result['score']:.1f}/1.0

üìä **Progress**: Question {next_q_num}/{total_q} ({result['progress']['current']}/{result['progress']['total']})

"""
            
            # Add next question
            if 'next_question' in result:
                response += "\n" + self._format_question_display(
                    type('Question', (), result['next_question'])(), 
                    next_q_num, 
                    total_q
                )
            
            return response
    
    def _provide_hint(self, session: Dict) -> str:
        """Provide hint for current question"""
        
        current_idx = session['current_question']
        if current_idx >= len(session['questions']):
            return "üéâ Assessment completed! No more questions."
        
        current_question = session['questions'][current_idx]
        
        if hasattr(current_question, 'hints') and current_question.hints:
            hint = current_question.hints[0]  # Show first hint
            return f"""
üí° **Hint for Current Question:**

{hint}

üß† **Think About:**
‚Ä¢ What data structure would be most efficient?
‚Ä¢ Can you solve this step by step?
‚Ä¢ Are there any edge cases to consider?

Ready to submit? Say "submit answer [your solution]"
"""
        
        else:
            return "üí≠ No specific hints available for this question, but here are some general tips:\n\n‚Ä¢ Break the problem into smaller parts\n‚Ä¢ Consider the constraints and edge cases\n‚Ä¢ Think about time and space complexity\n‚Ä¢ Start with a simple approach, then optimize"

# Create assessment agent instance
def AssessmentAgent(query: str) -> str:
    """Main function to handle assessment queries"""
    agent = AssessmentAgent()
    return agent.process_query(query)